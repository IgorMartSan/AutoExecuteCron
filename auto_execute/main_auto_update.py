from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import pandas as pd
from io import StringIO
import requests
import time
import schedule
import time
import tempfile


def coletar_dados_inmet(estacao_id="A511", data_inicio="01/01/2025", data_fim="01/05/2025"):
    with tempfile.TemporaryDirectory() as temp_dir:
        # Configurar o navegador (sem diret√≥rio de download porque n√£o vamos baixar nada)
        options = Options()
        options.add_argument(f"--user-data-dir={temp_dir}")
        # options.add_argument("--start-maximized")
        # options.add_argument("--headless=new")  # evita que o Chrome mande cabe√ßalho "webdriver"
        # options.add_argument("--headless")  # n√£o abre janela
        # options.add_argument("--disable-gpu")
        # options.add_argument("--no-sandbox")
        # options.add_argument("--window-size=1920,1080")  # simula tela "grande" invis√≠vel
        
        driver = webdriver.Chrome(options=options)
        

        try:
            # Acesse a p√°gina do INMET para dados da esta√ß√£o
            driver.get(f"https://tempo.inmet.gov.br/tabela/mapa/{estacao_id}/2025-05-20")
            time.sleep(3)

            # Preenche as datas nos inputs
            inputs = driver.find_elements(By.TAG_NAME, "input")
            if len(inputs) >= 2:
                inputs[0].clear()
                inputs[0].send_keys(data_inicio)
                inputs[1].clear()
                inputs[1].send_keys(data_fim)


            time.sleep(5)

            # Clica no bot√£o "Gerar Tabela"
            buttons = driver.find_elements(By.TAG_NAME, "button")

            # for btn in buttons:
            #     if "Gerar Tabela" in btn.text:
            #         btn.click()
            #         break

            # time.sleep(5)

            # Procura o link "Baixar CSV"
            links = driver.find_elements(By.TAG_NAME, "a")
            for link in links:
                if "Baixar CSV" in link.text:
                    csv_url = link.get_attribute("href")
                    print("üìé Link do CSV encontrado:", csv_url)

                    if csv_url.startswith("blob:"):
                        print("‚ö†Ô∏è Este link √© um BLOB URL, que s√≥ pode ser acessado dentro do navegador.")
                        print("   Use a abordagem de download com Selenium para capturar esse arquivo.")
                    else:
                        print("‚úÖ URL direta para CSV. Voc√™ pode usar requests ou pandas.read_csv com isso.")
                    break



            # 3. Clica em "Gerar Tabela"
            for btn in driver.find_elements(By.TAG_NAME, "button"):
                if "Gerar Tabela" in btn.text:
                    btn.click()
                    break



            # 4. Aguarda aparecer o bot√£o "Baixar CSV"
            WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.XPATH, "//a[contains(text(), 'Baixar CSV')]"))
            )

            # 5. Captura o link do blob
            blob_link = driver.find_element(By.XPATH, "//a[contains(text(), 'Baixar CSV')]")
            blob_url = blob_link.get_attribute("href")
            print("üìé blob URL:", blob_url)

            # 6. Executa um script ass√≠ncrono para ler o conte√∫do do blob
            script = """
                const url = arguments[0];
                const callback = arguments[1];
                fetch(url)
                    .then(res => res.text())
                    .then(data => callback(data))
                    .catch(err => callback("ERRO: " + err));
            """
            csv_content = driver.execute_async_script(script, blob_url)

            if csv_content.startswith("ERRO:"):
                raise Exception(csv_content)
            
            time.sleep(5)

            # 7. Converte para DataFrame e tratar os dados
            df = pd.read_csv(StringIO(csv_content), sep=";")

            colunas_desejadas = [
                'Data',
                'Hora (UTC)',
                'Temp. Max. (C)',
                'Temp. Min. (C)',
                'Pto Orvalho Max. (C)',
                'Pto Orvalho Min. (C)'
            ]

            df = df[colunas_desejadas]

        

            # ‚úÖ Renomear colunas para formato SYS_
            renomear = {
                'Temp. Max. (C)': 'SYS_TEMPERATURA_MAX',
                'Temp. Min. (C)': 'SYS_TEMPERATURA_MIN',
                'Pto Orvalho Max. (C)': 'SYS_PONTO_ORVALHO_MAX',
                'Pto Orvalho Min. (C)': 'SYS_PONTO_ORVALHO_MIN',
                'Data': 'Data',
                'Hora (UTC)': 'Hora (UTC)'
            }

            df = df.rename(columns=renomear)  

            df = df[list(renomear.values())]
            # Renomear colunas



            def converter_para_hora_utc(hora_str):
                hora_str = str(hora_str).zfill(4)  # Garante 4 d√≠gitos: ex: 0 -> 0000, 100 -> 0100
                return f"{hora_str[:2]}:{hora_str[2:]}:00"

            # Cria a coluna de datetime combinada
            df["Timestamp"] = pd.to_datetime(
                df["Data"] + " " + df["Hora (UTC)"].apply(converter_para_hora_utc),
                format="%d/%m/%Y %H:%M:%S"
            )

            # Converte para formato ISO 8601 com Z (UTC)
            df["Timestamp"] = df["Timestamp"].dt.strftime("%Y-%m-%dT%H:%M:%SZ")

            return df
        finally:
            driver.quit()

# ----------- Fun√ß√£o para obter WebId -----------
def get_webid_by_path(base_url: str, path: str) -> str:
    url = f"{base_url}/points?path={path}"
    try:
        response = requests.get(url, verify=False)
        response.raise_for_status()
        return response.json()["WebId"]
    except Exception as e:
        print(f"Erro ao obter WebId para {path}: {e}")
        return ""

# ----------- Fun√ß√£o para enviar valores -----------
def send_recorded_values(base_url: str, webid: str, values: list) -> bool:
    url = f"{base_url}/streams/{webid}/recorded"
    headers = {"Content-Type": "application/json"}
    try:
        response = requests.post(url, headers=headers, json=values, verify=False)
        response.raise_for_status()
        print(f"Enviado com sucesso para WebId: {webid}")
        return True
    except Exception as e:
        print(f"Erro ao enviar para {webid}: {e}")
        print(response.text if response else "sem resposta")
        return False

# ------------------ Coleta de dados m√™s a m√™s ------------------
def main():
    from datetime import datetime
    from calendar import monthrange

    dados = []

    # Data atual
    hoje = datetime.utcnow().date()
    ano_atual = hoje.year
    mes_atual = hoje.month
    dia_hoje = hoje.day

    # Define data de in√≠cio (primeiro dia do m√™s atual)
    data_inicio = f"{mes_atual:02d}/01/{ano_atual}"

    # Define data de fim (hoje)
    data_fim = f"{mes_atual:02d}/{dia_hoje:02d}/{ano_atual}"

    print(f"üìÖ Coletando de {data_inicio} at√© {data_fim}...")

    try:
        df_mensal = coletar_dados_inmet(estacao_id="A511", data_inicio=data_inicio, data_fim=data_fim)
        df_mensal = df_mensal.dropna()
        if not df_mensal.empty:
            dados.append(df_mensal)
            print(f"‚úÖ Coletado: {len(df_mensal)} linhas.")
        else:
            print("‚ö†Ô∏è Nenhum dado encontrado.")
    except Exception as e:
        print(f"‚ùå Falha ao coletar {mes_atual:02d}/{ano_atual}: {e}")

    df = df_mensal.dropna()

    # Substitui v√≠rgula por ponto e converte para float
    for col in ["SYS_TEMPERATURA_MAX", "SYS_TEMPERATURA_MIN", "SYS_PONTO_ORVALHO_MAX", "SYS_PONTO_ORVALHO_MIN"]:
        df[col] = df[col].str.replace(",", ".").astype(float)

    # ----------- Configura√ß√µes -----------
    base_url = "http://10.247.224.39/piwebapi"
    pims_prefix = "\\\\pims\\"

    # ----------- Obter WebIds -----------
    webid_map = {
        "SYS_TEMPERATURA_MAX": get_webid_by_path(base_url, f"{pims_prefix}SYS_TEMPERATURA_MAX"),
        "SYS_TEMPERATURA_MIN": get_webid_by_path(base_url, f"{pims_prefix}SYS_TEMPERATURA_MIN"),
        "SYS_PONTO_ORVALHO_MAX": get_webid_by_path(base_url, f"{pims_prefix}SYS_PONTO_ORVALHO_MAX"),
        "SYS_PONTO_ORVALHO_MIN": get_webid_by_path(base_url, f"{pims_prefix}SYS_PONTO_ORVALHO_MIN"),
    }

    print("igor123")


    # ----------- Enviar dados para cada tag -----------
    for tag, webid in webid_map.items():
        if not webid:
            continue  # pula se o WebId falhar

        valores_para_enviar = [
            {"Timestamp": row["Timestamp"], "Value": row[tag]}
            for _, row in df.iterrows()
            if pd.notnull(row[tag])
        ]

        send_recorded_values(base_url, webid, valores_para_enviar)

# import schedule
# import time


if __name__ == "__main__":
    # while True:
    #     print("üöÄ Executando coleta...")
    #     try:
            main()
        #     print("‚úÖ Coleta finalizada!")
        # except Exception as e:
        #     print(f"‚ùå Erro na execu√ß√£o: {e}")

        # timer = 3600*8
        
        # print(f"‚è≥ Aguardando {timer/3600} hora(s) para pr√≥xima execu√ß√£o...")
        # time.sleep(timer)  # 3600 segundos = 1 hora







